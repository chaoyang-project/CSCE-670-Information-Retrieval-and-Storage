{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "\n",
    "# Homework 4:  Word Embeddings for Information Retrieval and Query Expansion\n",
    "\n",
    "### 100 points [5% of your final grade]\n",
    "\n",
    "### Due: April 28, 2020 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* In this homework you will improve your information retrieval engine in homework 1 by word embeddings to: (i) directly match the query and the document in the latent semantic space of word embeddings; (ii) expand the original query via word embeddings.\n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw4.ipynb`. For example, my homework submission would be something like `555001234_hw4.ipynb`. Submit this notebook via eCampus (look for the homework 1 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the total allotted to you).\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Dataset and Parsing (The same as Homework 1)\n",
    "\n",
    "The dataset is collected from Quizlet (https://quizlet.com), a website where users can generated their own flashcards. Each flashcard generated by a user is made up of an entity on the front and a definition describing or explaining the entity correspondingly on the back. We treat entities on each flashcard's front as the queries and the definitions on the back of flashcards as the documents. Definitions (documents) are relevant to an entity (query) if the definitions are from the back of the entity's flashcard; otherwise definitions are not relevant. **In this homework, queries and entities are interchangeable as well as documents and definitions.**\n",
    "\n",
    "The format of the dataset is like this:\n",
    "\n",
    "**query \\t document id \\t document**\n",
    "\n",
    "Examples:\n",
    "\n",
    "decision tree\t\\t 27946 \\t\tshow complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\n",
    "\n",
    "where \"decision tree\" is the entity in the front of a flashcard and \"show complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\" is the definition on the flashcard's back and \"27946\" is the id of the definition. Naturally, this document is relevant to the query.\n",
    "\n",
    "false positive rate\t\\t 686\t\\t fall-out; probability of a false alarm\n",
    "\n",
    "where document 686 is not relevant to query \"decision tree\" because the entity of \"fall-out; probability of a false alarm\" is \"false positive rate\".\n",
    "\n",
    "For parsing this dataset, you could also just copy your code from homework 1 to complete the following tasks:\n",
    "* Tokenize documents (definitions) using **whitespaces and punctuations as delimiters**.\n",
    "* Remove stop words: use nltk stop words list (from nltk.corpus import stopwords)\n",
    "* Stemming: use [nltk Porter stemmer](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter)\n",
    "* Remove any other strings that you think are less informative or nosiy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "f = open(\"homework_1_data.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "strings = ''\n",
    "corpus = []\n",
    "while line:\n",
    "    line_list = line.split(\"\\t\")\n",
    "    string = re.sub(\"[^A-Z^a-z^0-9^ ]\", \" \", line_list[2])\n",
    "\n",
    "    line_words = nltk.word_tokenize(string)\n",
    "    filtered_line_words = [line_word for line_word in line_words if line_word not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    line_singles = [stemmer.stem(line_plural) for line_plural in filtered_line_words]\n",
    "    line_singles_no_digits = []\n",
    "    for x in line_singles:\n",
    "        if not x.isdigit():\n",
    "            line_singles_no_digits.append(x)\n",
    "\n",
    "    corpus.append(line_singles_no_digits)\n",
    "    line = f.readline()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Word2Vec (30 points)\n",
    "\n",
    "In this part you will use the Word2Vec algorithm to generate word embeddings for tokens in the dataset. You can just use a package like https://radimrehurek.com/gensim/models/word2vec.html. Let's set the size of word embeddings to be 20. Please print the word embeddings for the tokens: \n",
    "* relational\n",
    "* database\n",
    "* garbage\n",
    "* collection\n",
    "* retrieval \n",
    "* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here.\n",
    "# how do you generate the word embeddings\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(corpus, size=20, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = model.wv \n",
    "del model \n",
    "wv.save('word_vector') \n",
    "loaded_wv = KeyedVectors.load('word_vector', mmap='r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the word embeddings of the six tokens\n",
    "def print_word_embeddings(word):\n",
    "    stemmer = PorterStemmer()\n",
    "    stem = stemmer.stem(word)\n",
    "    print(\"The word embedding for:\", word)\n",
    "    print(wv[stem],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word embedding for: relational\n",
      "[ 2.1185431  -1.7910612   2.3100224  -3.8898535   0.95128983 -1.6378244\n",
      "  0.1950791   0.29736868 -1.1256076  -0.12825722  1.9100384   1.6876783\n",
      "  0.15590088  1.1038716   1.5969405  -2.4179933  -0.19025594 -0.22537753\n",
      "  0.6726891  -0.23532271] \n",
      "\n",
      "The word embedding for: database\n",
      "[ 2.3996198  -0.5639794   0.79490227 -4.1667533   1.0665674  -1.4387202\n",
      " -1.287428    0.47218665 -1.8812461   0.61816096  2.1934264   0.5602395\n",
      "  0.57601064 -0.06206043  1.5491109  -3.4975069   1.4149612  -2.2815917\n",
      "  2.357336    0.4816189 ] \n",
      "\n",
      "The word embedding for: garbage\n",
      "[ 0.23065002 -0.2146568   0.31055576 -0.17249243  0.24463701 -0.2938342\n",
      " -0.09150504  0.325075   -0.2880192   0.16644886  0.28005844 -0.00961642\n",
      "  0.18499838 -0.00350569  0.04795637  0.00319307 -0.01125147 -0.05349322\n",
      "  0.37475586  0.25783548] \n",
      "\n",
      "The word embedding for: collection\n",
      "[ 2.3029718   0.05625704  2.0099719  -3.3979063   0.9960767  -1.6817203\n",
      " -1.2647372   1.7185093  -1.1941811   0.87113434  1.2482647   0.79504347\n",
      "  0.8154095  -2.0078354   1.2277217  -1.4829068   1.2786834  -0.96500266\n",
      " -0.31765062  0.39034626] \n",
      "\n",
      "The word embedding for: retrieval\n",
      "[ 1.8444388   0.04649413  0.9394624  -2.4630053   1.3656923  -0.8898899\n",
      " -1.7282732   0.8882349  -1.289319    1.6220708   2.3308175  -0.5917596\n",
      "  0.555214   -1.8745252   0.94512266 -1.4946057   1.323711   -1.9748265\n",
      "  0.883788   -0.46435258] \n",
      "\n",
      "The word embedding for: model\n",
      "[-0.8776747  -1.359839    0.84959453 -2.9877267  -0.1854228  -2.0154586\n",
      " -1.4285187   2.2818615  -0.15770373 -1.4290458  -0.04399792 -0.8023936\n",
      " -0.8421868   1.9846097   2.1248682  -1.8535945  -0.9828982   0.0992626\n",
      "  1.8997017   1.1809703 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_word_embeddings('relational')\n",
    "print_word_embeddings('database')\n",
    "print_word_embeddings('garbage')\n",
    "print_word_embeddings('collection')\n",
    "print_word_embeddings('retrieval')\n",
    "print_word_embeddings('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Vector Space Model via Word Embeddings (40 points) \n",
    "\n",
    "In this part, your job is to match the query and the document via the cosine similarity between the embeddings of them.\n",
    "\n",
    "Since there are not just one token in a query or a document, the first challenge is how to aggregate many word embeddings into one embedding of a query or a document. There are many ways to do so: \n",
    "* Max pooling: return the maximum value along each dimension of a bunch of word embeddings. For example, [1, 3, 4], [2, 1, 5] -> [2, 3, 5].\n",
    "* Min pooling: return the minimum value along each dimension of a bunch of word embeddings\n",
    "* Mean pooling: return the mean value along each dimension of a bunch of word embeddings\n",
    "* Sum: element-wise add a bunch of word embeddings together\n",
    "* Weighted sum: assign weights to word embeddings and then add them together. Weights could be TF, IDF or TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "f = open(\"homework_1_data.txt\", encoding='UTF-8')             \n",
    "f2 = open(\"definition.txt\", 'w', encoding='UTF-8')\n",
    "\n",
    "line = f.readline()             \n",
    "strings = ''\n",
    "while line:\n",
    "    line_list = line.split(\"\\t\")\n",
    "    string = re.sub(\"[^A-Z^a-z^0-9^ ]\", \" \", line_list[2])\n",
    "    strings = strings + string\n",
    "\n",
    "    line_words = nltk.word_tokenize(string)\n",
    "    filtered_line_words = [line_word for line_word in line_words if line_word not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    line_singles = [stemmer.stem(line_plural) for line_plural in filtered_line_words]\n",
    "    line_singles_no_digits = []\n",
    "    for x in line_singles:\n",
    "        if not x.isdigit():\n",
    "            line_singles_no_digits.append(x)\n",
    "    # list -> string\n",
    "    list_to_string = \" \".join(line_singles_no_digits)\n",
    "    f2.write(list_to_string+\"\\n\")\n",
    "\n",
    "    line = f.readline()\n",
    "\n",
    "f.close()\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(strings)\n",
    "filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "stemmer = PorterStemmer()\n",
    "singles = [stemmer.stem(plural) for plural in filtered_words]\n",
    "\n",
    "singles_no_digits = []\n",
    "for x in singles:\n",
    "    if not x.isdigit():\n",
    "        singles_no_digits.append(x)\n",
    "\n",
    "term_freq_dist = nltk.FreqDist(singles_no_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relat\n",
      "databas\n",
      "garbag\n",
      "collect\n",
      "retriev\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('relational'))\n",
    "print(stemmer.stem('database'))\n",
    "print(stemmer.stem('garbage'))\n",
    "print(stemmer.stem('collection'))\n",
    "print(stemmer.stem('retrieval'))\n",
    "print(stemmer.stem('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The docID of 'relational database':\n",
      "[28128, 28129, 28130, 28131, 28132, 28133, 28134, 28135, 28136, 28137, 28138, 28139, 28140, 28141, 28142, 28143, 28144, 28145, 28146, 28147, 28148, 28149, 28150, 28151, 28152, 28153, 28154, 28155, 28156, 28157, 28158, 28159, 28160, 28161, 28162, 28163, 28164, 28165, 28166, 28167, 28168, 28169, 28170, 28171, 28172, 28173, 28174, 28175, 28176, 28177, 28178, 28179, 28180, 28181, 28182, 28183, 28184, 28185, 28186, 28187, 28188, 28189, 28190, 28191, 28192, 28193, 28194, 28195, 28196, 28197, 28198, 28199, 28200, 28201, 28202, 28203, 28204, 28205, 28206, 28207, 28208, 28209, 28210, 28211, 28212, 28213, 28214, 28215, 28216, 28217, 28218, 28219, 28220, 28221, 28222, 28223, 28224, 28225, 28226, 28227, 28228, 28229, 28230, 28231, 28232, 28233, 28234, 28235, 28236, 28237, 28238, 28239, 28240, 28241, 28242, 28243, 28244, 28245, 28246, 28247, 28248, 28249, 28250, 28251, 28252, 28253, 28254, 28255, 28256, 28257, 28258, 28259, 28260, 28261, 28262, 28263, 28264, 28265, 28266, 28267, 28268, 28269, 28270, 28271, 28272, 28273, 28274, 28275, 28276, 28277, 28278, 28279, 28280, 28281, 28282, 28283, 28284, 28285, 28286, 28287, 28288, 28289, 28290, 28291, 28292, 28293, 28294, 28295, 28296, 28297, 28298, 28299, 28300, 28301, 28302, 28303, 28304, 28305, 28306, 28307, 28308, 28309, 28310, 28311, 28312, 28313, 28314, 28315, 28316, 28317, 28318, 28319, 28320, 28321, 28322, 28323, 28324, 28325, 28326, 28327, 28328, 28329, 28330, 28331, 28332, 28333, 28334, 28335, 28336, 28337, 28338, 28339, 28340, 28341, 28342, 28343, 28344, 28345, 28346, 28347, 28348, 28349, 28350, 28351, 28352, 28353, 28354, 28355, 28356, 28357, 28358, 28359, 28360, 28361, 28362, 28363, 28364, 28365, 28366, 28367, 28368, 28369, 28370, 28371, 28372, 28373, 28374, 28375, 28376, 28377, 28378, 28379, 28380, 28381, 28382, 28383, 28384, 28385, 28386, 28387, 28388, 28389, 28390, 28391, 28392, 28393, 28394, 28395, 28396, 28397, 28398, 28399, 28400, 28401, 28402, 28403, 28404, 28405, 28406, 28407, 28408, 28409, 28410, 28411]\n"
     ]
    }
   ],
   "source": [
    "# save the docID of 'relational database' in list_1\n",
    "f = open(\"homework_1_data.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "ID = 0\n",
    "list_1 = []\n",
    "while line:\n",
    "    line_list = line.split(\"\\t\")\n",
    "    if \"relational database\" == line_list[0]:\n",
    "        list_1.append(ID)\n",
    "        ID += 1\n",
    "    else:\n",
    "        ID += 1\n",
    "        \n",
    "    line = f.readline()\n",
    "   \n",
    "f.close()\n",
    "print(\"The docID of 'relational database':\") \n",
    "print(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The docID of 'garbage collection':\n",
      "[21543, 21544, 21545, 21546, 21547, 21548, 21549, 21550, 21551, 21552, 21553, 21554, 21555, 21556, 21557, 21558, 21559, 21560, 21561, 21562, 21563, 21564, 21565, 21566, 21567, 21568, 21569, 21570, 21571, 21572, 21573, 21574, 21575, 21576, 21577, 21578, 21579, 21580]\n"
     ]
    }
   ],
   "source": [
    "# save the docID of 'garbage collection' in list_2\n",
    "f = open(\"homework_1_data.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "ID = 0\n",
    "list_2 = []\n",
    "while line:\n",
    "    line_list = line.split(\"\\t\")\n",
    "    if \"garbage collection\" == line_list[0]:\n",
    "        list_2.append(ID)\n",
    "        ID += 1\n",
    "    else:\n",
    "        ID += 1\n",
    "        \n",
    "    line = f.readline()\n",
    "   \n",
    "f.close()\n",
    "print(\"The docID of 'garbage collection':\") \n",
    "print(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The docID of 'retrieval model':\n",
      "[13961, 13962]\n"
     ]
    }
   ],
   "source": [
    "# save the docID of 'retrieval model' in list_3\n",
    "f = open(\"homework_1_data.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "ID = 0\n",
    "list_3 = []\n",
    "while line:\n",
    "    line_list = line.split(\"\\t\")\n",
    "    if \"retrieval model\" == line_list[0]:\n",
    "        list_3.append(ID)\n",
    "        ID += 1\n",
    "    else:\n",
    "        ID += 1\n",
    "        \n",
    "    line = f.readline()\n",
    "   \n",
    "f.close()\n",
    "print(\"The docID of 'retrieval model':\") \n",
    "print(list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of cosine similarity\n",
    "import numpy as np\n",
    "def cos_sim(vector_a, vector_b):\n",
    "    if np.linalg.norm(vector_a)==0 or np.linalg.norm(vector_b)==0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        vector_a = vector_a / np.linalg.norm(vector_a)\n",
    "        vector_b = vector_b / np.linalg.norm(vector_b)\n",
    "        cosine = vector_a.dot(vector_b)\n",
    "        return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Max pooling word embeddings for documents\n",
    "# save it in doc_Max_pooling\n",
    "f = open(\"definition.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "doc_Max_pooling = []\n",
    "while line:\n",
    "    line = line.strip()    \n",
    "    line_list = line.split()\n",
    "    if line_list:\n",
    "        temp = list(wv[line_list[0]])\n",
    "        for i in range(len(line_list)-1):\n",
    "            for j in range(20):\n",
    "                temp[j] = max(temp[j], wv[line_list[i+1]][j])\n",
    "        \n",
    "        doc_Max_pooling.append(temp)\n",
    "        line = f.readline()\n",
    "    else:\n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        doc_Max_pooling.append(temp)\n",
    "        line = f.readline()    \n",
    "   \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision_Max(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(max(wv[word1][i], wv[word2][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Max_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Max_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    precision = len(merge_list)/10\n",
    "\n",
    "    print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_pooling method:\n",
      "Precision@10 for query: relational database:   0.2\n",
      "Precision@10 for query: garbage collection:    0.0\n",
      "Precision@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Max_pooling method:\")\n",
    "print(\"Precision@10 for query: relational database:   \", end='')\n",
    "print_precision_Max(\"relat\", \"databas\", list_1)\n",
    "print(\"Precision@10 for query: garbage collection:    \", end='')\n",
    "print_precision_Max(\"garbag\", \"collect\", list_2)\n",
    "print(\"Precision@10 for query: retrieval model:       \", end='')\n",
    "print_precision_Max(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Min pooling word embeddings for documents\n",
    "# save it in doc_Min_pooling\n",
    "f = open(\"definition.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "doc_Min_pooling = []\n",
    "while line:\n",
    "    line = line.strip()    \n",
    "    line_list = line.split()\n",
    "    if line_list:\n",
    "        temp = list(wv[line_list[0]])\n",
    "        for i in range(len(line_list)-1):\n",
    "            for j in range(20):\n",
    "                temp[j] = min(temp[j], wv[line_list[i+1]][j])\n",
    "        \n",
    "        doc_Min_pooling.append(temp)\n",
    "        line = f.readline()\n",
    "    else:\n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        doc_Min_pooling.append(temp)\n",
    "        line = f.readline()    \n",
    "   \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision_Min(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(min(wv[word1][i], wv[word2][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Min_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Min_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    precision = len(merge_list)/10\n",
    "\n",
    "    print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_pooling method:\n",
      "Precision@10 for query: relational database:   0.3\n",
      "Precision@10 for query: garbage collection:    0.0\n",
      "Precision@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min_pooling method:\")\n",
    "print(\"Precision@10 for query: relational database:   \", end='')\n",
    "print_precision_Min(\"relat\", \"databas\", list_1)\n",
    "print(\"Precision@10 for query: garbage collection:    \", end='')\n",
    "print_precision_Min(\"garbag\", \"collect\", list_2)\n",
    "print(\"Precision@10 for query: retrieval model:       \", end='')\n",
    "print_precision_Min(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Mean pooling word embeddings for documents\n",
    "# save it in doc_Mean_pooling\n",
    "f = open(\"definition.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "doc_Mean_pooling = []\n",
    "while line:\n",
    "    line = line.strip()    \n",
    "    line_list = line.split()\n",
    "    if line_list:        \n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        for k in range(20):\n",
    "            temp[k] = 1/20 * wv[line_list[0]][k]\n",
    "        for i in range(len(line_list)-1):\n",
    "            for j in range(20):\n",
    "                temp[j] = temp[j] + 1/20 * wv[line_list[i+1]][j]                \n",
    "        \n",
    "        doc_Mean_pooling.append(temp)\n",
    "        line = f.readline()\n",
    "    else:\n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        doc_Mean_pooling.append(temp)\n",
    "        line = f.readline()    \n",
    "   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision_Mean(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append((wv[word1][i] + wv[word2][i])/2)\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Mean_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Mean_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    precision = len(merge_list)/10\n",
    "\n",
    "    print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_pooling method:\n",
      "Precision@10 for query: relational database:   0.6\n",
      "Precision@10 for query: garbage collection:    0.0\n",
      "Precision@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean_pooling method:\")\n",
    "print(\"Precision@10 for query: relational database:   \", end='')\n",
    "print_precision_Mean(\"relat\", \"databas\", list_1)\n",
    "print(\"Precision@10 for query: garbage collection:    \", end='')\n",
    "print_precision_Mean(\"garbag\", \"collect\", list_2)\n",
    "print(\"Precision@10 for query: retrieval model:       \", end='')\n",
    "print_precision_Mean(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Sum word embeddings for documents\n",
    "# save it in doc_Sum\n",
    "f = open(\"definition.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "doc_Sum = []\n",
    "while line:\n",
    "    line = line.strip()    \n",
    "    line_list = line.split()\n",
    "    if line_list:        \n",
    "        temp = list(wv[line_list[0]])\n",
    "        for i in range(len(line_list)-1):\n",
    "            for j in range(20):\n",
    "                temp[j] = temp[j] + wv[line_list[i+1]][j]\n",
    "        \n",
    "        doc_Sum.append(temp)\n",
    "        line = f.readline()\n",
    "    else:\n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        doc_Sum.append(temp)\n",
    "        line = f.readline()    \n",
    "   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision_Sum(word1, word2, truth):  \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(wv[word1][i] + wv[word2][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    precision = len(merge_list)/10\n",
    "\n",
    "    print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum method:\n",
      "Precision@10 for query: relational database:   0.6\n",
      "Precision@10 for query: garbage collection:    0.0\n",
      "Precision@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum method:\")\n",
    "print(\"Precision@10 for query: relational database:   \", end='')\n",
    "print_precision_Sum(\"relat\", \"databas\", list_1)\n",
    "print(\"Precision@10 for query: garbage collection:    \", end='')\n",
    "print_precision_Sum(\"garbag\", \"collect\", list_2)\n",
    "print(\"Precision@10 for query: retrieval model:       \", end='')\n",
    "print_precision_Sum(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the Weighted Sum word embeddings for documents\n",
    "# save it in doc_Weighted_Sum\n",
    "f = open(\"definition.txt\", encoding='UTF-8')\n",
    "line = f.readline()\n",
    "doc_Weighted_Sum = []\n",
    "while line:\n",
    "    line = line.strip()    \n",
    "    line_list = line.split()\n",
    "    if line_list:        \n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        for k in range(20):\n",
    "            temp[k] = term_freq_dist[line_list[0]] * wv[line_list[0]][k]\n",
    "        for i in range(len(line_list)-1):\n",
    "            for j in range(20):\n",
    "                temp[j] = temp[j] + term_freq_dist[line_list[i+1]] * wv[line_list[i+1]][j]                \n",
    "        \n",
    "        doc_Weighted_Sum.append(temp)\n",
    "        line = f.readline()\n",
    "    else:\n",
    "        temp = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        doc_Weighted_Sum.append(temp)\n",
    "        line = f.readline()    \n",
    "   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision_Weighted_Sum(word1, word2, truth):  \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(term_freq_dist[word1] * wv[word1][i] + term_freq_dist[word2] * wv[word2][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Weighted_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Weighted_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    precision = len(merge_list)/10\n",
    "\n",
    "    print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum method:\n",
      "Precision@10 for query: relational database:   0.2\n",
      "Precision@10 for query: garbage collection:    0.0\n",
      "Precision@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Sum method:\")\n",
    "print(\"Precision@10 for query: relational database:   \", end='')\n",
    "print_precision_Weighted_Sum(\"relat\", \"databas\", list_1)\n",
    "print(\"Precision@10 for query: garbage collection:    \", end='')\n",
    "print_precision_Weighted_Sum(\"garbag\", \"collect\", list_2)\n",
    "print(\"Precision@10 for query: retrieval model:       \", end='')\n",
    "print_precision_Weighted_Sum(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different aggregation methods and report the precision@10 for these queries:\n",
    "* query: relational database\n",
    "* query: garbage collection\n",
    "* query: retrieval model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Among these aggregation methods, which one is the best and which one is the worst?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Max:    0.2, 0, 0\n",
    "   \n",
    "   Min:     0.3, 0, 0\n",
    "   \n",
    "   Mean:  0.6, 0, 0\n",
    "   \n",
    "   Sum:    0.6, 0, 0\n",
    "   \n",
    " Weighted Sum:  0.2, 0, 0\n",
    "### So, Mean and Sum are the best, Max and Weighted Sum are the worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Query Expansion via Word Embeddings (30 points) \n",
    "Remember the hardest query \"retrieval model\" in homework 1? Because there is no document containing \"retrieval model\" in the dataset, you cannot retrieve any documents by Boolean matching. Now, it is the time of your \"revenge\" via query expansion.\n",
    "\n",
    "In this part, your job is to expand the original query like \"retrieval model\" by adding semantically similar words (e.g., \"search\"), which are selected from all tokens in the dataset.\n",
    "\n",
    "There are many ways to do so. For this part, we want you to calculate the cosine similarity between each of the original query tokens and the other tokens based on their word embeddings.\n",
    "\n",
    "First, please find the top 3 similar tokens for:\n",
    "* relational\n",
    "* database\n",
    "* garbage\n",
    "* collection\n",
    "* retrieval \n",
    "* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar tokens and their similarities\n",
      "relational:\n",
      "[('entiti', 0.9473505020141602), ('certifi', 0.9239091873168945), ('tabl', 0.9139374494552612)]\n",
      "database:\n",
      "[('dbm', 0.9263573884963989), ('od', 0.9236255288124084), ('cleans', 0.9000288248062134)]\n",
      "garbage:\n",
      "[('later', 0.9856059551239014), ('reorgan', 0.9844050407409668), ('fan', 0.9817262887954712)]\n",
      "collection:\n",
      "[('repositori', 0.9401402473449707), ('warehous', 0.9266716241836548), ('gather', 0.9155275821685791)]\n",
      "retrieval:\n",
      "[('store', 0.9658225774765015), ('updat', 0.9093206524848938), ('warehous', 0.904878556728363)]\n",
      "model:\n",
      "[('mathemat', 0.9043813943862915), ('formal', 0.8658748865127563), ('conceptu', 0.8592434525489807)]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(\"Top 3 similar tokens and their similarities\")\n",
    "print(\"relational:\")\n",
    "print(wv.similar_by_word(\"relat\", topn=3))\n",
    "print(\"database:\")\n",
    "print(wv.similar_by_word(\"databas\", topn=3))\n",
    "print(\"garbage:\")\n",
    "print(wv.similar_by_word(\"garbag\", topn=3))\n",
    "print(\"collection:\")\n",
    "print(wv.similar_by_word(\"collect\", topn=3))\n",
    "print(\"retrieval:\")\n",
    "print(wv.similar_by_word(\"retriev\", topn=3))\n",
    "print(\"model:\")\n",
    "print(wv.similar_by_word(\"model\", topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, please add these similar tokens to the orignal query and redo the **vector space model** in part 2. \n",
    "* query: relational database\n",
    "* query: garbage collection\n",
    "* query: retrieval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_pooling method:\n",
      "Recall@10 for query: relational database:   0.007042253521126761\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Max(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(max(wv[word1][i], wv[word2][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Max_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Max_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "\n",
    "    \n",
    "print(\"Max_pooling method:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Max(\"relat\", \"databas\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Max(\"garbag\", \"collect\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Max(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_pooling method:\n",
      "Recall@10 for query: relational database:   0.01056338028169014\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Min(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(min(wv[word1][i], wv[word2][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Min_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Min_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "\n",
    "\n",
    "print(\"Min_pooling method:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Min(\"relat\", \"databas\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Min(\"garbag\", \"collect\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Min(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_pooling method:\n",
      "Recall@10 for query: relational database:   0.02112676056338028\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Mean(word1, word2, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append((wv[word1][i] + wv[word2][i])/2)\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Mean_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Mean_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Mean_pooling method:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Mean(\"relat\", \"databas\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Mean(\"garbag\", \"collect\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Mean(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum method:\n",
      "Recall@10 for query: relational database:   0.02112676056338028\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Sum(word1, word2, truth):  \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(wv[word1][i] + wv[word2][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Sum method:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Sum(\"relat\", \"databas\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Sum(\"garbag\", \"collect\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Sum(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum method:\n",
      "Recall@10 for query: relational database:   0.007042253521126761\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Weighted_Sum(word1, word2, truth):  \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(term_freq_dist[word1] * wv[word1][i] + term_freq_dist[word2] * wv[word2][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Weighted_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Weighted_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Weighted Sum method:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Weighted_Sum(\"relat\", \"databas\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Weighted_Sum(\"garbag\", \"collect\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Weighted_Sum(\"retriev\", \"model\", list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------------------------------Expansion--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_pooling method after Expansion:\n",
      "Recall@10 for query: relational database:   0.02112676056338028\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Max_Expansion(word1, word2, word3, word4, word5, word6, word7, word8, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(max(wv[word1][i], wv[word2][i], wv[word3][i], wv[word4][i], wv[word5][i], wv[word6][i], wv[word7][i], wv[word8][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Max_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Max_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "\n",
    "    \n",
    "print(\"Max_pooling method after Expansion:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Max_Expansion(\"relat\", \"databas\", \"entiti\", \"certifi\", \"tabl\", \"dbm\", \"od\", \"cleans\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Max_Expansion(\"garbag\", \"collect\", \"later\", \"reorgan\", \"fan\", \"repositori\", \"warehous\", \"gather\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Max_Expansion(\"retriev\", \"model\", \"store\", \"updat\", \"warehous\", \"mathemat\", \"formal\", \"conceptu\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_pooling method after Expansion:\n",
      "Recall@10 for query: relational database:   0.017605633802816902\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Min_Expansion(word1, word2, word3, word4, word5, word6, word7, word8, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(min(wv[word1][i], wv[word2][i], wv[word3][i], wv[word4][i], wv[word5][i], wv[word6][i], wv[word7][i], wv[word8][i]))\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Min_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Min_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "\n",
    "\n",
    "print(\"Min_pooling method after Expansion:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Min_Expansion(\"relat\", \"databas\", \"entiti\", \"certifi\", \"tabl\", \"dbm\", \"od\", \"cleans\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Min_Expansion(\"garbag\", \"collect\", \"later\", \"reorgan\", \"fan\", \"repositori\", \"warehous\", \"gather\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Min_Expansion(\"retriev\", \"model\", \"store\", \"updat\", \"warehous\", \"mathemat\", \"formal\", \"conceptu\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_pooling method after Expansion:\n",
      "Recall@10 for query: relational database:   0.028169014084507043\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Mean_Expansion(word1, word2, word3, word4, word5, word6, word7, word8, truth):\n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append((wv[word1][i] + wv[word2][i] + wv[word3][i] + wv[word4][i] + wv[word5][i] + wv[word6][i] + wv[word7][i] + wv[word8][i])/8)\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Mean_pooling)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Mean_pooling[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Mean_pooling method after Expansion:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Mean_Expansion(\"relat\", \"databas\", \"entiti\", \"certifi\", \"tabl\", \"dbm\", \"od\", \"cleans\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Mean_Expansion(\"garbag\", \"collect\", \"later\", \"reorgan\", \"fan\", \"repositori\", \"warehous\", \"gather\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Mean_Expansion(\"retriev\", \"model\", \"store\", \"updat\", \"warehous\", \"mathemat\", \"formal\", \"conceptu\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum method after Expansion:\n",
      "Recall@10 for query: relational database:   0.028169014084507043\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Sum_Expansion(word1, word2, word3, word4, word5, word6, word7, word8, truth): \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(wv[word1][i] + wv[word2][i] + wv[word3][i] + wv[word4][i] + wv[word5][i] + wv[word6][i] + wv[word7][i] + wv[word8][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Sum method after Expansion:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Sum_Expansion(\"relat\", \"databas\", \"entiti\", \"certifi\", \"tabl\", \"dbm\", \"od\", \"cleans\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Sum_Expansion(\"garbag\", \"collect\", \"later\", \"reorgan\", \"fan\", \"repositori\", \"warehous\", \"gather\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Sum_Expansion(\"retriev\", \"model\", \"store\", \"updat\", \"warehous\", \"mathemat\", \"formal\", \"conceptu\", list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum method after Expansion:\n",
      "Recall@10 for query: relational database:   0.02464788732394366\n",
      "Recall@10 for query: garbage collection:    0.0\n",
      "Recall@10 for query: retrieval model:       0.0\n"
     ]
    }
   ],
   "source": [
    "def print_recall_Weighted_Sum_Expansion(word1, word2, word3, word4, word5, word6, word7, word8, truth): \n",
    "    query_list = []\n",
    "    for i in range(20):\n",
    "        query_list.append(term_freq_dist[word1] * wv[word1][i] + term_freq_dist[word2] * wv[word2][i] + term_freq_dist[word3] * wv[word3][i] + term_freq_dist[word4] * wv[word4][i] + term_freq_dist[word5] * wv[word5][i] + term_freq_dist[word6] * wv[word6][i] + term_freq_dist[word7] * wv[word7][i] + term_freq_dist[word8] * wv[word8][i])\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    for i in range(len(doc_Weighted_Sum)):\n",
    "        cos_sim_list.append(cos_sim(query_list, doc_Weighted_Sum[i]))\n",
    "    \n",
    "    cos_sim_dict = {}\n",
    "    for i in range(len(cos_sim_list)):\n",
    "        cos_sim_dict[i] = cos_sim_list[i]\n",
    "    sorted_cos_sim_dict = dict(sorted(cos_sim_dict.items(), key=lambda d: d[1], reverse=True))\n",
    "    sorted_keys_list = list(sorted_cos_sim_dict.keys())\n",
    "    top10_list = []\n",
    "    for i in range(10):\n",
    "        top10_list.append(sorted_keys_list[i])\n",
    "\n",
    "    merge_list = list(set(truth).intersection(set(top10_list)))\n",
    "    recall = len(merge_list)/len(truth)\n",
    "\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "print(\"Weighted Sum method after Expansion:\")\n",
    "print(\"Recall@10 for query: relational database:   \", end='')\n",
    "print_recall_Weighted_Sum_Expansion(\"relat\", \"databas\", \"entiti\", \"certifi\", \"tabl\", \"dbm\", \"od\", \"cleans\", list_1)\n",
    "print(\"Recall@10 for query: garbage collection:    \", end='')\n",
    "print_recall_Weighted_Sum_Expansion(\"garbag\", \"collect\", \"later\", \"reorgan\", \"fan\", \"repositori\", \"warehous\", \"gather\", list_2)\n",
    "print(\"Recall@10 for query: retrieval model:       \", end='')\n",
    "print_recall_Weighted_Sum_Expansion(\"retriev\", \"model\", \"store\", \"updat\", \"warehous\", \"mathemat\", \"formal\", \"conceptu\", list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report recall@10 before the query expansion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Max:  0.007042253521126761, 0, 0\n",
    "   \n",
    "   Min:  0.01056338028169014, 0, 0\n",
    "   \n",
    "   Mean: 0.02112676056338028, 0, 0\n",
    "   \n",
    "   Sum:  0.02112676056338028, 0, 0\n",
    "   \n",
    " Weighted Sum:  0.007042253521126761, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report recall@10 after the query expansion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Max:  0.02112676056338028, 0, 0\n",
    "   \n",
    "   Min:  0.017605633802816902, 0, 0\n",
    "   \n",
    "   Mean: 0.028169014084507043, 0, 0\n",
    "   \n",
    "   Sum:  0.028169014084507043, 0, 0\n",
    "   \n",
    " Weighted Sum:  0.02464788732394366, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Why we measure recall here instead of precision or NDCG?\n",
    "\n",
    "Should the tokens added for expansion have the same importance as the original query tokens? If not, how to improve the query expansion in this part?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, some queries such as \"retrieval model\" has only two lines(13961 and 13962). It is not reasonable to compute precision@10 or NDCG@10 for this query.\n",
    "\n",
    "The tokens added for expansion do not have the same importance as the original query tokens. When aggregating the word embeddings into one embedding of a query, assign weights to the tokens added for expansion such as the similarity of the token with the original token."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
